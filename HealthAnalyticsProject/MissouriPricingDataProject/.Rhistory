install.packages(c("backports", "BH", "boot", "broom", "classInt", "cluster", "codetools", "colorspace", "curl", "data.table", "digest", "evaluate", "foreign", "formatR", "gdalUtils", "ggplot2", "gridExtra", "hexbin", "highr", "htmltools", "htmlwidgets", "httpuv", "knitr", "lattice", "lazyeval", "leaflet", "lubridate", "mapproj", "maps", "markdown", "MASS", "Matrix", "mgcv", "munsell", "ngram", "NLP", "openssl", "packrat", "pillar", "PKI", "purrr", "R.oo", "raster", "RCurl", "reshape2", "rgdal", "RgoogleMaps", "rJava", "rjson", "rlang", "rmarkdown", "rpart", "rprojroot", "rsconnect", "RWeka", "RWekajars", "shiny", "sourcetools", "sp", "survival", "tm", "units", "utf8", "withr", "yaml"))
gm <- gapminder
library(shiny)
library(ggplot2)
library(dplyr)
library(gapminder)
?tabsetPanel
install.packages("gapminder")
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
install.packages("shinythemes")
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
?sliderInput
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
?inputSlider
?sliderInput
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
?helpText
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
runApp('Documents/MIZZOU/DataVizII/GapMinderExercise')
install.packages("rtweet")
library(rtweet)
rt <- search_tweets(
"#rstats", n = 18000, include_rts = FALSE
)
rt
users_data(rt)
str(users_data(rt))
library(ggplot2)
ts_plot(rt)
ts_plot(rt, "3 hours") +
ggplot2::theme_minimal() +
ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
ggplot2::labs(
x = NULL, y = NULL,
title = "Frequency of #rstats Twitter statuses from past 9 days",
subtitle = "Twitter status (tweet) counts aggregated using three-hour intervals",
caption = "\nSource: Data collected from Twitter's REST API via rtweet"
)
rt <- search_tweets(
"lang:en", geocode = lookup_coords("usa"), n = 10000
)
cnn_fds <- get_friends("cnn")
cnn_fds_data <- lookup_users(cnn_fds$user_id)
View(cnn_fds_data)
tmls <- get_timelines(c("cnn", "BBCWorld", "foxnews"), n = 3200)
## plot the frequency of tweets for each user over time
tmls %>%
dplyr::filter(created_at > "2017-10-29") %>%
dplyr::group_by(screen_name) %>%
ts_plot("days", trim = 1L) +
ggplot2::geom_point() +
ggplot2::theme_minimal() +
ggplot2::theme(
legend.title = ggplot2::element_blank(),
legend.position = "bottom",
plot.title = ggplot2::element_text(face = "bold")) +
ggplot2::labs(
x = NULL, y = NULL,
title = "Frequency of Twitter statuses posted by news organization",
subtitle = "Twitter status (tweet) counts aggregated by day from October/November 2017",
caption = "\nSource: Data collected from Twitter's REST API via rtweet"
)
?search_tweets
?tweets_data
?get_timeline
djt <- get_timeline("realDonaldTrump", n = 3200)
## data frame where each observation (row) is a different tweet
djt
View(djt)
library(tidyverse)
today <- today(tzone = "EST")
library(lubridate)
today <- today(tzone = "EST")
str(djt$created_at)
str(Sys.time)
Sys.time()
Sys.time - 7
Sys.time() -(7*60*60*24)
lastweek <- djt %>%
filter(created_at > (Sys.time() -(7*60*60*24)))
View(lastweek)
totaltweets <- nrows(lastweek)
totaltweets <- nrow(lastweek)
mostfavorited <- lastweek[max(lastweek$favorite_count), "tweet"]
mostfavorited <- lastweek[max(lastweek$favorite_count), "text"]
View(mostfavorited)
mostfavorited <- max(lastweek$favorite_count)
mostfavorited <- lastweek$text[favorite_count == max(lastweek$favorite_count)]
mostfavorited <- lastweek$text[lastweek$favorite_count == max(lastweek$favorite_count)]
leastfavorited <- lastweek$text[lastweek$favorite_count == min(lastweek$favorite_count)]
mostretweeted <- lastweek$text[lastweek$favorite_count == max(lastweek$retweet_count)]
mostretweeted <- lastweek$text[lastweek$retweet_count == max(lastweek$retweet_count)]
leastretweeted <- lastweek$text[lastweek$retweet_count == min(lastweek$retweet_count)]
mostretweeted
leastfavorited
mostfavorited <- lastweek$text[lastweek$favorite_count == max(lastweek$favorite_count)][1]
leastfavorited <- lastweek$text[lastweek$favorite_count == min(lastweek$favorite_count)][1]
mostretweeted <- lastweek$text[lastweek$retweet_count == max(lastweek$retweet_count)][1]
leastretweeted <- lastweek$text[lastweek$retweet_count == min(lastweek$retweet_count)][1]
#define function
extract.hashes = function(vec){
hash.pattern = "#[[:alpha:]]+"
have.hash = grep(x = vec, pattern = hash.pattern)
hash.matches = gregexpr(pattern = hash.pattern,
text = vec[have.hash])
extracted.hash = regmatches(x = vec[have.hash], m = hash.matches)
df = data.frame(table(tolower(unlist(extracted.hash))))
colnames(df) = c("tag","freq")
df = df[order(df$freq,decreasing = TRUE),]
return(df)
}
#get hashtag data
dat = head(extract.hashes(lastweek$text),50)
dat2 = transform(dat,tag = reorder(tag,freq))
View(dat2)
View(dat)
#get hashtag data
dat = extract.hashes(lastweek$text)
dat2 = transform(dat,tag = reorder(tag,freq))
## plot time series of tweets
ts_plot(lastweek, "3 hours") +
ggplot2::theme_minimal() +
ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
ggplot2::labs(
x = NULL, y = NULL,
title = "Frequency of @realDonaldTrump tweets from past 9 days",
subtitle = "Twitter status (tweet) counts aggregated using three-hour intervals",
caption = "\nSource: Data collected from Twitter's REST API via rtweet"
)
tweets <- lastweek$text
cleantweets <- gsub("http.*"|"https.*"|"#.*"|"@.*", tweets)
cleantweets <- gsub("http.*|https.*|#.*|@.*", x = tweets)
?gsub
cleantweets <- gsub(pattern = "http.*|https.*|#.*|@.*",
replacement = "",
x = tweets)
head(tweets)
head(cleantweets)
head(tweets, 10)
tweets <- lastweek$text
#get rid of unnecessary spaces
clean_tweet <- str_replace_all(tweets," "," ")
# Get rid of URLs
clean_tweet <- str_replace_all(clean_tweet, "http://t.co/[a-z,A-Z,0-9]*{8}","")
tweets <- lastweek$text
#get rid of unnecessary spaces
clean_tweet <- str_replace_all(tweets," "," ")
# Get rid of URLs
clean_tweet <- str_replace_all(clean_tweet, "http://t.co/[a-z,A-Z,0-9]*","")
# Take out retweet header, there is only one
clean_tweet <- str_replace(clean_tweet,"RT @[a-z,A-Z]*: ","")
# Get rid of hashtags
clean_tweet <- str_replace_all(clean_tweet,"#[a-z,A-Z]*","")
# Get rid of references to other screennames
clean_tweet <- str_replace_all(clean_tweet,"@[a-z,A-Z]*","")
# Get rid of &
clean_tweet = gsub("&amp", "", unclean_tweet)
tweets <- lastweek$text
#get rid of unnecessary spaces
clean_tweet <- str_replace_all(tweets," "," ")
# Get rid of URLs
clean_tweet <- str_replace_all(clean_tweet, "http://t.co/[a-z,A-Z,0-9]*","")
# Take out retweet header, there is only one
clean_tweet <- str_replace(clean_tweet,"RT @[a-z,A-Z]*: ","")
# Get rid of hashtags
clean_tweet <- str_replace_all(clean_tweet,"#[a-z,A-Z]*","")
# Get rid of references to other screennames
clean_tweet <- str_replace_all(clean_tweet,"@[a-z,A-Z]*","")
# Get rid of &
clean_tweet = gsub("&amp", "", clean_tweet)
# Get rid of punctuation
clean_tweet = gsub("[[:punct:]]", "", clean_tweet)
# Get rid of digits
clean_tweet = gsub("[[:digit:]]", "", clean_tweet)
tweets <- lastweek$text
#get rid of unnecessary spaces
clean_tweet <- str_replace_all(tweets," "," ")
# Get rid of URLs
clean_tweet <- str_replace_all(clean_tweet, "http://t.co/[a-z,A-Z,0-9]*","")
# Take out retweet header, there is only one
clean_tweet <- str_replace(clean_tweet,"RT @[a-z,A-Z]*: ","")
# Get rid of hashtags
clean_tweet <- str_replace_all(clean_tweet,"#[a-z,A-Z]*","")
# Get rid of references to other screennames
clean_tweet <- str_replace_all(clean_tweet,"@[a-z,A-Z]*","")
# Get rid of &
clean_tweet = gsub("&amp", "", clean_tweet)
# Get rid of punctuation
clean_tweet = gsub("[[:punct:]]", "", clean_tweet)
# Get rid of digits
clean_tweet = gsub("[[:digit:]]", "", clean_tweet)
tweets
clean_tweet
tweets <- lastweek$text
#get rid of unnecessary spaces
clean_tweet <- str_replace_all(tweets," "," ")
# Get rid of URLs
clean_tweet <- str_replace_all(clean_tweet, "http(s?)://t.co/[a-z,A-Z,0-9]*","")
# Take out retweet header, there is only one
clean_tweet <- str_replace(clean_tweet,"RT @[a-z,A-Z]*: ","")
# Get rid of hashtags
clean_tweet <- str_replace_all(clean_tweet,"#[a-z,A-Z]*","")
# Get rid of references to other screennames
clean_tweet <- str_replace_all(clean_tweet,"@[a-z,A-Z]*","")
# Get rid of &
clean_tweet = gsub("&amp", "", clean_tweet)
# Get rid of punctuation
clean_tweet = gsub("[[:punct:]]", "", clean_tweet)
# Get rid of digits
clean_tweet = gsub("[[:digit:]]", "", clean_tweet)
clean_tweet
install.packages("syuzhet")
library(syuzhet)
corpus <- clean_tweet
emotions <- get_nrc_sentiment(corpus)
text_emotions <- cbind(corpus, emotions)
head(text_emotions)
View(emotions)
corpus <- clean_tweet
emotions <- get_sentiment(corpus)
text_emotions <- cbind(corpus, emotions)
head(text_emotions)
text_emotions <- as.data.frame(cbind(corpus, emotions))
head(text_emotions)
corpus <- clean_tweet
sentiment <- get_sentiment(corpus)
text_sentiment <- as.data.frame(cbind(corpus, sentiment))
head(text_sentiment)
most_positive <- corpus[sentiment == max(sentiment)]
most_positive
least_positive <- corpus[sentiment <= min(sentiment)]
least_positive
positive_tweets <- corpus[sentiment > 0]
negative_tweets <- corpus[sentiment < 0]
neutral_tweets <- corpus[sentiment == 0]
category_sentiment <- ifelse(sentiment < 0, "Negative", ifelse(sentiment > 0, "Positive", "Neutral"))
table(category_sentiment)
?get_sentiment
corpus <- get_sentences(clean_tweet)
sentiment <- get_sentiment(corpus)
text_sentiment <- as.data.frame(cbind(corpus, sentiment))
head(text_sentiment)
most_positive <- corpus[sentiment == max(sentiment)]
most_positive
least_positive <- corpus[sentiment <= min(sentiment)]
least_positive
positive_tweets <- corpus[sentiment > 0]
negative_tweets <- corpus[sentiment < 0]
neutral_tweets <- corpus[sentiment == 0]
category_sentiment <- ifelse(sentiment < 0, "Negative", ifelse(sentiment > 0, "Positive", "Neutral"))
table(category_sentiment)
## get most recent 3200 tweets posted by Donald Trump's account
nasa <- get_timeline("NASA", n = 3200)
lastweek <- nasa %>%
filter(created_at > (Sys.time() -(7*60*60*24))) #here, subtracting 7 days time from user's current datetime
## plot time series of tweets
ts_plot(lastweek, "3 hours") +
ggplot2::theme_minimal() +
ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
ggplot2::labs(
x = NULL, y = NULL,
title = "Frequency of @realDonaldTrump tweets from past 9 days",
subtitle = "Twitter status (tweet) counts aggregated using three-hour intervals",
caption = "\nSource: Data collected from Twitter's REST API via rtweet"
)
totaltweets <- nrow(lastweek)
mostfavorited <- lastweek$text[lastweek$favorite_count == max(lastweek$favorite_count)][1]
leastfavorited <- lastweek$text[lastweek$favorite_count == min(lastweek$favorite_count)][1]
mostretweeted <- lastweek$text[lastweek$retweet_count == max(lastweek$retweet_count)][1]
leastretweeted <- lastweek$text[lastweek$retweet_count == min(lastweek$retweet_count)][1]
#define function
extract.hashes = function(vec){
hash.pattern = "#[[:alpha:]]+"
have.hash = grep(x = vec, pattern = hash.pattern)
hash.matches = gregexpr(pattern = hash.pattern,
text = vec[have.hash])
extracted.hash = regmatches(x = vec[have.hash], m = hash.matches)
df = data.frame(table(tolower(unlist(extracted.hash))))
colnames(df) = c("tag","freq")
df = df[order(df$freq,decreasing = TRUE),]
return(df)
}
#get hashtag data
dat = extract.hashes(lastweek$text)
dat2 = transform(dat,tag = reorder(tag,freq))
tweets <- lastweek$text
#get rid of unnecessary spaces
clean_tweet <- str_replace_all(tweets," "," ")
# Get rid of URLs
clean_tweet <- str_replace_all(clean_tweet, "http(s?)://t.co/[a-z,A-Z,0-9]*","")
# Take out retweet header, there is only one
clean_tweet <- str_replace(clean_tweet,"RT @[a-z,A-Z]*: ","")
# Get rid of hashtags
clean_tweet <- str_replace_all(clean_tweet,"#[a-z,A-Z]*","")
# Get rid of references to other screennames
clean_tweet <- str_replace_all(clean_tweet,"@[a-z,A-Z]*","")
# Get rid of &
clean_tweet = gsub("&amp", "", clean_tweet)
# Get rid of punctuation
clean_tweet = gsub("[[:punct:]]", "", clean_tweet)
# Get rid of digits
clean_tweet = gsub("[[:digit:]]", "", clean_tweet)
corpus <- get_sentences(clean_tweet)
sentiment <- get_sentiment(corpus)
text_sentiment <- as.data.frame(cbind(corpus, sentiment))
head(text_sentiment)
most_positive <- corpus[sentiment == max(sentiment)]
most_positive
least_positive <- corpus[sentiment <= min(sentiment)]
least_positive
positive_tweets <- corpus[sentiment > 0]
negative_tweets <- corpus[sentiment < 0]
neutral_tweets <- corpus[sentiment == 0]
category_sentiment <- ifelse(sentiment < 0, "Negative", ifelse(sentiment > 0, "Positive", "Neutral"))
table(category_sentiment)
rm(cleantweets)
## plot time series of tweets
ts_plot(lastweek, "3 hours") +
ggplot2::theme_minimal() +
ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
ggplot2::labs(
x = NULL, y = NULL,
title = "Frequency of @NASA tweets from past 9 days",
subtitle = "Twitter status (tweet) counts aggregated using three-hour intervals",
caption = "\nSource: Data collected from Twitter's REST API via rtweet"
)
View(dat2)
View(nasa)
#get hashtag data
hashtable <- transform(extract.hashes(lastweek$text),tag = reorder(tag,freq))
tophashtag <- hashtable[1,1]
View(hashtable)
tophashtag <- hashtable$tag[1]
tophashtag <- as.character(hashtable$tag[1])
shiny::runApp('Documents/R projects/NASALastWeekApp')
census_api_key("e209eaedec5f34caf642425c214931727ebaeb39")
library(tidycensus)
library(tidycensus)
library(tidyverse)
library(tidycensus)
install.packages("sf")
install.packages("sf")
library(sf)
library(tidycensus)
install.packages(c("data.table", "dplyr", "forcats", "ggplot2", "ggthemes", "httr", "knitr", "purrr", "readr", "readxl", "rmarkdown", "rsconnect", "shiny", "shinythemes", "stringr", "tibble", "tidyr", "tidyselect"))
install.packages(c("data.table", "dplyr", "forcats", "ggplot2", "ggthemes", "httr", "knitr", "purrr", "readr", "readxl", "rmarkdown", "rsconnect", "shiny", "shinythemes", "stringr", "tibble", "tidyr", "tidyselect"))
install.packages(c("data.table", "dplyr", "forcats", "ggplot2", "ggthemes", "httr", "knitr", "purrr", "readr", "readxl", "rmarkdown", "rsconnect", "shiny", "shinythemes", "stringr", "tibble", "tidyr", "tidyselect"))
library(sf)
library(tidyverse)
library(tidycensus)
tidyverse_update(recursive = TRUE)
install.packages("askpass")
tidyverse_update(recursive = TRUE)
install.packages("ellipsis")
tidyverse_update(recursive = TRUE)
install.packages("fansi")
tidyverse_update(recursive = TRUE)
install.packages("fs")
tidyverse_update(recursive = TRUE)
install.packages("generics")
tidyverse_update(recursive = TRUE)
install.packages("prettyunits")
tidyverse_update(recursive = TRUE)
install.packages("progress")
tidyverse_update(recursive = TRUE)
install.packages("ps")
tidyverse_update(recursive = TRUE)
install.packages("xfun")
tidyverse_update(recursive = TRUE)
setwd("~/Documents/MIZZOU/HealthAnalyticsProject/MissouriPricingDataProject")
shiny::runApp()
